<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/white/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"default"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"disqus","storage":true,"lazyload":false,"nav":{"disqus":{"text":"Load Disqus","order":-1}},"activeClass":"disqus"},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="前言 在 DeepSeek 的帮助下，读论文DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning，利用蒙特卡罗方法和深度强化学习实现的斗地主 AI DouZero。 顺便试试新安装的 Mermaid  渲染插件。">
<meta property="og:type" content="article">
<meta property="og:title" content="读论文DouZero">
<meta property="og:url" content="http://example.com/post/20250410232647.html">
<meta property="og:site_name" content="LeeKa 的酒馆">
<meta property="og:description" content="前言 在 DeepSeek 的帮助下，读论文DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning，利用蒙特卡罗方法和深度强化学习实现的斗地主 AI DouZero。 顺便试试新安装的 Mermaid  渲染插件。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2025/04/17/Z7zcpJSbBwG2guI.png">
<meta property="og:image" content="https://pic2.zhimg.com/v2-a02c7c880ec2b62d427cf8d4616805ed_1440w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/v2-42e7c90a4d44b7620e2856a3074613ef_1440w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/v2-0c273cbb717cd472ecf1a047c20a98b7_1440w.jpg">
<meta property="og:image" content="https://pic3.zhimg.com/v2-a615a148cc832df1bf6941a52b3c16ac_1440w.jpg">
<meta property="og:image" content="https://s2.loli.net/2025/04/30/fH3u7V9lmNjKznE.png">
<meta property="article:published_time" content="2025-04-10T15:26:47.000Z">
<meta property="article:modified_time" content="2025-06-13T13:24:47.325Z">
<meta property="article:author" content="LeeKa">
<meta property="article:tag" content="蒙特卡洛方法">
<meta property="article:tag" content="强化学习">
<meta property="article:tag" content="斗地主">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="读论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2025/04/17/Z7zcpJSbBwG2guI.png">


<link rel="canonical" href="http://example.com/post/20250410232647.html">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/post/20250410232647.html","path":"post/20250410232647.html","title":"读论文DouZero"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>读论文DouZero | LeeKa 的酒馆</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">LeeKa 的酒馆</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">欢迎，旅人！坐下来享受一下暖烘烘的炉火吧。</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-友链"><a href="/links/" rel="section"><i class="fa-solid fa-link fa-fw"></i>友链</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text"> 前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E8%83%8C%E6%99%AF"><span class="nav-number">2.</span> <span class="nav-text"> 一些背景</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%8F%AF%E4%BB%A5%E8%A7%A3%E5%86%B3%E6%96%97%E5%9C%B0%E4%B8%BB%E9%97%AE%E9%A2%98"><span class="nav-number">2.1.</span> <span class="nav-text"> 为什么强化学习可以解决斗地主问题？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%AD%A4%E5%89%8D%E5%9C%A8%E6%96%97%E5%9C%B0%E4%B8%BB%E4%B8%AD%E9%9D%A2%E4%B8%B4%E4%BA%86%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98"><span class="nav-number">2.2.</span> <span class="nav-text"> 强化学习此前在斗地主中面临了什么问题？</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#douzero%E7%9A%84%E7%AE%97%E6%B3%95%E9%80%BB%E8%BE%91"><span class="nav-number">3.</span> <span class="nav-text"> DouZero的算法逻辑</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%BB%E4%BB%A3%E7%A0%81"><span class="nav-number">4.</span> <span class="nav-text"> 读代码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#train"><span class="nav-number">4.1.</span> <span class="nav-text"> train()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#act"><span class="nav-number">4.2.</span> <span class="nav-text"> act()</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E5%87%BA%E7%89%8Cforward"><span class="nav-number">4.2.1.</span> <span class="nav-text"> 预测出牌：forward()</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E6%93%8D%E4%BD%9Cstep"><span class="nav-number">4.2.2.</span> <span class="nav-text"> 执行操作：step()</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%A0%E9%80%92%E4%BF%A1%E6%81%AF"><span class="nav-number">4.2.3.</span> <span class="nav-text"> 传递信息</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#batch_and_learn"><span class="nav-number">4.3.</span> <span class="nav-text"> batch_and_learn()</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">5.</span> <span class="nav-text"> 参考文献</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LeeKa"
      src="https://s2.loli.net/2022/03/24/zcq6l9KENbRJtDi.jpg">
  <p class="site-author-name" itemprop="name">LeeKa</p>
  <div class="site-description" itemprop="description">代码、音乐和游戏，一起来聊聊吧</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">71</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">182</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/KXAND" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;KXAND" rel="noopener me" target="_blank">GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:leeka.Pub@outlook.com" title="E-Mail → mailto:leeka.Pub@outlook.com" rel="noopener me" target="_blank">E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/QuiXand" title="X → https:&#x2F;&#x2F;twitter.com&#x2F;QuiXand" rel="noopener me" target="_blank">X</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://pinhua.leeka.pub/" title="宁远平话 → https:&#x2F;&#x2F;pinhua.leeka.pub" rel="noopener me" target="_blank">宁远平话</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/big/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/post/20250410232647.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://s2.loli.net/2022/03/24/zcq6l9KENbRJtDi.jpg">
      <meta itemprop="name" content="LeeKa">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LeeKa 的酒馆">
      <meta itemprop="description" content="代码、音乐和游戏，一起来聊聊吧">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="读论文DouZero | LeeKa 的酒馆">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          读论文DouZero<a href="https://github.com/KXAND/BlogSource/edit/source/_posts/%E8%AF%BB%E8%AE%BA%E6%96%87DouZero.md" class="post-edit-link" title="编辑" rel="noopener" target="_blank"><i class="fa fa-pen-nib"></i></a>
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-10 23:26:47" itemprop="dateCreated datePublished" datetime="2025-04-10T23:26:47+08:00">2025-04-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-06-13 21:24:47" itemprop="dateModified" datetime="2025-06-13T21:24:47+08:00">2025-06-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">强化学习</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/post/20250410232647.html#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="post/20250410232647.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4.4k</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h2>
<p>在 DeepSeek 的帮助下，读论文<em>DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning</em>，利用蒙特卡罗方法和深度强化学习实现的斗地主 AI <strong>DouZero</strong>。 <s>顺便试试新安装的 Mermaid  渲染插件。</s><span id="more"></span></p>
<h2 id="一些背景"><a class="markdownIt-Anchor" href="#一些背景"></a> 一些背景</h2>
<h3 id="为什么强化学习可以解决斗地主问题"><a class="markdownIt-Anchor" href="#为什么强化学习可以解决斗地主问题"></a> 为什么强化学习可以解决斗地主问题？</h3>
<p>在本科时接触到的<strong>监督学习</strong>中，AI 是通过阅读大量的数据，来学习哪些是正确的操作，那些是错误的操作。在这个概念上，又细分出了完全监督、弱监督、无监督，分别指代数据集完全被标注好、数据集标注有误或不完全等、AI自行归纳打标签等情况。但是，总的来说它们都是从静态的数据中进行学习，然后针对环境给出一次反馈就行了。</p>
<p>但是在游戏等互动环境中情况并不是这样的，AI 每进行一次操作，环境就发生一次改变。监督学习总不可能针对每一种情况对进行训练，那完全不切实际。而这就是强化学习所试图解决的问题。如下图所示</p>
<pre><code class="highlight mermaid">graph TB
AI--①执行动作--&gt;环境
环境--②改变 AI 所处的状态--&gt;AI
环境--③给予 AI 动作的奖励--&gt;AI</code></pre>
<p>AI会不断给出动作，然后环境告诉 AI 发生了什么变化，AI 因此获得什么奖励。AI 的目标是追求奖励最大化。</p>
<blockquote>
<p>见参考 3，蘑菇书第一章。</p>
</blockquote>
<p>在斗地主中，玩家不断地丢出手牌（动作），对手也会据此打出自己的手牌（状态变化），直到有人手牌率先打光，就赢了（奖励）。这正是强化学习的逻辑。</p>
<h3 id="强化学习此前在斗地主中面临了什么问题"><a class="markdownIt-Anchor" href="#强化学习此前在斗地主中面临了什么问题"></a> 强化学习此前在斗地主中面临了什么问题？</h3>
<p>DouZero 团队指出，斗地主有非常大的状态空间和动作空间，而此前的 RL 研究主要关注的还是情况更简单状态空间更小的情况，如蘑菇书第一章图1.25提到的OpenAI Gym库中内置的这些小游戏：</p>
<p><img src="https://s2.loli.net/2025/04/17/Z7zcpJSbBwG2guI.png" alt="图 0" /></p>
<p>不仅如此，斗地主还需要同时讲究配合（农民和农民）和对抗（农民和地主），而且需要非常多步才能决出最后的胜者，这些特点都需要针对性的处理。综合考虑这些特性，Douzero 团队提出了 Deep Monte-Carol（DMC） 方法，即神经网络来生成蒙特卡洛动作。他们指出，相比于策略梯度方法，DMC 可以更好地利用已知动作去推断未知动作的奖励状态（例如， <em>K 带 3</em> 如果是一个有奖励的操作，那么可以猜测 <em>J 带 3</em> 也是一个不错的操作）。而相比于 DQN（Deep Q-learning）， DMC 不仅能更轻松的处理这么大的动作空间和长游戏步骤，价值估计还是无偏的。因为 DMC 采用的是蒙特卡洛方法，而 DQN 中有取最大值的操作，因此会有些偏高。</p>
<p>当然，蒙特卡洛方法作为一种简单暴力的算法，它也有它的不足，那就是随机采样的结果太多样了，需要较多的采样次数才能收敛，因此往往并不高效。但是 DouZero 团队相信，通过并行训练的手段，DMC 可以快速采集样本，从而解决大量采样耗时长的问题。</p>
<h2 id="douzero的算法逻辑"><a class="markdownIt-Anchor" href="#douzero的算法逻辑"></a> DouZero的算法逻辑</h2>
<p>通常在 RL 中使用蒙特卡洛算法过程如下</p>
<ol start="0">
<li>初始化。有一个值为零的价值表 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 表；有一个随机生成的策略 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span> 指示在给定状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> 下需要采取的动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span>。、</li>
<li>生成一场对局（episode），其中玩家使用的策略是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span>，得到的回报是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span>。</li>
<li>把对局中的状态动作对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 表值依据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> 更新。例如多局游戏中都有这个状态动作对时，对得到的多个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> 取均值.</li>
<li>更新策略。策略<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>s</mi><mo stretchy="false">)</mo><mo>←</mo><mi mathvariant="normal">arg max</mi><mo>⁡</mo><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(s)\larr\argmax Q(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">a</span><span class="mord mathrm">r</span><span class="mord mathrm" style="margin-right:0.01389em;">g</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathrm">m</span><span class="mord mathrm">a</span><span class="mord mathrm">x</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span>，即策略更新采取为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">s</span></span></span></span> 状态下采用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 表中该状态下价值最大的动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> 。</li>
</ol>
<p>当然，我们无法直接应用到斗地主问题上————那样的话这篇论文也就不需要存在了。研究者对算法做了一些修改以适应问题需要，具体来说包括：引入神经网络代替 Q 表、对牌型编码、设计并行的演员采样机制。</p>
<p>首先，由于斗地主的状态空间很大，维护一个巨大的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 表不现实。而且前面提到的泛化也无法实现，因为 <em>K 带 3</em> 和 <em>J 带 3</em> 显然是两个格子里的值，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span>表无法体现出二者在状态空间中的相似性。因此 DouZero 中将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 表换成了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 神经网络。</p>
<p>Q 网络接收动作和状态，然后告诉我们对应的 Q 值。这样，我们就需要将动作和状态进行编码，并且定义哪些信息是<strong>状态</strong>。</p>
<p>此外，我们还需要将动作和手牌等编码为一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>13</mn></mrow><annotation encoding="application/x-tex">4\times 13</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">3</span></span></span></span> 的矩阵如下，其中的 0/1 值代表是否包含这张牌。</p>
<p><img src="https://pic2.zhimg.com/v2-a02c7c880ec2b62d427cf8d4616805ed_1440w.jpg" alt="牌型编码" /></p>
<p>而我们给网络输入的状态信息则如下，其中包括牌桌上可以观察到的信息的编码，也包括历史出牌信息的编码。对牌桌上可以观察到的信息（例如另外两家余下的手牌，已经出的牌等）编码和上面的矩阵自然是一样的。历史出牌信息则通过 LSTM （长短时记忆网络）进行编码。</p>
<p><img src="https://pic4.zhimg.com/v2-42e7c90a4d44b7620e2856a3074613ef_1440w.jpg" alt="v2-42e7c90a4d44b7620e2856a3074613ef_1440w.jpg (1440×1000)" /></p>
<p>上图还告诉我们，Q 网络是一个六层的 MLP（多层感知器） 结构，或者叫全连接网络，因为 MLP 中每层都全连接到下一层。</p>
<p>第二步中我们还需要更新 Q 网络。这里，DouZero 采取了 MSE（Mean Square Error）方法，即<strong>均方差损失</strong>，它的公式如下</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>×</mo><mo>∑</mo><mo stretchy="false">(</mo><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi><mtext>–</mtext><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MSE = \frac{1}{n}\times \sum(actual – prediction)^2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.6000100000000002em;vertical-align:-0.55001em;"></span><span class="mop op-symbol large-op" style="position:relative;top:-0.000004999999999977245em;">∑</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord">–</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中真实值（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">actual</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span></span></span></span>）为实际交互得到的回报值，预测值（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">prediction</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span></span></span></span>）为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 网络给出的当前动作状态对的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">Q</span></span></span></span> 值。</p>
<p>更具体地，在实现上，训练被分成了两个大逻辑板块。</p>
<p>第一个是 <em>执行器</em> <em>(Actor)</em> 的逻辑，它负责第 0 步和第 1 步，即玩游戏采样数据并写入一个共享缓冲区中。如前所述将斗地主中的三人命名为 <strong>L</strong>（地主，landlord）、<strong>U</strong> （地主上家，Up）和<strong>D</strong>（地主下家，Down）。那么每局游戏中都在同时训练三个位置上的 Actor。它们被一定程度地区隔开来以免互相影响，并且如前所述，采用多线程同时让多个 Actor 采集数据加快速度。Actor 的逻辑如下。</p>
<p><img src="https://pic4.zhimg.com/v2-0c273cbb717cd472ecf1a047c20a98b7_1440w.jpg" alt="Actor Thread" /></p>
<p>第二个就是 <em>学习器（Leaner）</em> ，它负责第 3 步和第 4 步。即不断从缓冲区中提取数据，学习并更新 Q 网络。</p>
<p><img src="https://pic3.zhimg.com/v2-a615a148cc832df1bf6941a52b3c16ac_1440w.jpg" alt="Learner Thread" /></p>
<h2 id="读代码"><a class="markdownIt-Anchor" href="#读代码"></a> 读代码</h2>
<p>上面这些其实算是对论文和对应知乎专栏文章的复读。下面对应读代码解析。</p>
<h3 id="train"><a class="markdownIt-Anchor" href="#train"></a> train()</h3>
<p>由 <code>train.py</code> 进入 <code>dmc.py</code> 中的 <code>train()</code> 函数是主函数。它首先根据参数（<code>flags</code>）确定有多少可供 <code>actor</code> 训练的设备（<code>devices</code>），并对应初始化数据结构。如果 <code>flags</code> 中有要求导入模型并继续训练，还需要导入对应的训练检查点（line 61 - 144）。</p>
<p>初始化的数据结构中有以下比较重要：</p>
<ul>
<li>position: 一个字符串，表示玩家的身份：地主（L）、地主上家（U）、地主下家（D）。</li>
<li><code>models</code>: 一个字典，包含 <code>device</code> 个 <code>Model</code> 结构，Model 中则对应存储了三个位置（L、U、D）的模型等信息。这是给 <code>actor</code> 用的。</li>
<li><code>buffers</code>[]：缓冲区，即 <code>actor</code> 写入， <code>learner</code> 读出的共享数据区。大小为 <code>devices</code> * <code>position</code>(L,U,D) 个。</li>
<li><code>learner_model</code>：顾名思义，给 <code>learner</code> 用的模型。运行在 <code>flags</code> 中指定的 <code>training_device</code> 上。</li>
<li><code>locks</code>, <code>position_lock</code> ：线程锁，<code>locks</code> 共 <code>devices</code> * 3（L/U/D）把，用于锁定 <code>actors</code> 写入的 <code>buffers</code>；<code>position_lock</code> 共 3 把（L/U/D），用于锁定 <code>learner_model</code> 的对应 <code>position。</code></li>
<li><code>free_queue</code> 和 <code>full_queue</code> <code>：buffers</code> 状态指示。由于各 <code>actor</code> 和 <code>learner</code> 都属于不同线程，所以我们需要锁保证通信的稳定。<code>free_queue</code> 标识了那些空闲的 buffer 区，<code>full_queue</code> 标识了被填满的那些 buffer 区。<s>一度以为是表示“全部的buffer”，但是这里 full 取的是“满了”（have been filled）的意思</s></li>
</ul>
<p>随后，程序启动 <code>devices</code> * <code>num_actors</code> 个 <code>actor</code> 线程，即同一个 <code>device</code> 下有 <code>num_actors</code> 个 <code>actor</code> 使用同一个 <code>model</code> 进行游戏。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Starting actor processes</span></span><br><span class="line"><span class="keyword">for</span> device <span class="keyword">in</span> device_iterator:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(flags.num_actors):</span><br><span class="line">        actor = ctx.Process(</span><br><span class="line">            target=act,</span><br><span class="line">            args=(i, device, free_queue[device], full_queue[device], models[device], buffers[device], flags))</span><br><span class="line">        actor.start()</span><br><span class="line">        actor_processes.append(actor)</span><br></pre></td></tr></table></figure>
<p>当然为了让 <code>actor</code> 有地方可写，我们需要先给 <code>free_queue</code> 中放入一些位置：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> device <span class="keyword">in</span> device_iterator:</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(flags.num_buffers):</span><br><span class="line">        free_queue[device][<span class="string">&#x27;landlord&#x27;</span>].put(m)</span><br><span class="line">        free_queue[device][<span class="string">&#x27;landlord_up&#x27;</span>].put(m)</span><br><span class="line">        free_queue[device][<span class="string">&#x27;landlord_down&#x27;</span>].put(m)</span><br></pre></td></tr></table></figure>
<p>然后我们启动 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>devices</mtext><mo>×</mo><mtext>num_threads</mtext><mo>×</mo><mtext>position</mtext></mrow><annotation encoding="application/x-tex">\text{devices}\times\text{num\_threads}\times \text{position}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord text"><span class="mord">devices</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord text"><span class="mord">num_threads</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8623000000000001em;vertical-align:-0.19444em;"></span><span class="mord text"><span class="mord">position</span></span></span></span></span> 个 <code>learner</code> 线程，即同一个 device下每 <code>num_threads</code> 个线程里，都有 3 个（<code>position</code> 个） <code>learner</code> 针对不同的 <code>position</code> 学习。他们的的学习结果更新到唯一的 <code>learner_model</code> 中不同的 <code>position</code> 上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> device <span class="keyword">in</span> device_iterator:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(flags.num_threads):</span><br><span class="line">        <span class="keyword">for</span> position <span class="keyword">in</span> [<span class="string">&#x27;landlord&#x27;</span>, <span class="string">&#x27;landlord_up&#x27;</span>, <span class="string">&#x27;landlord_down&#x27;</span>]:</span><br><span class="line">            thread = threading.Thread(</span><br><span class="line">                target=batch_and_learn, name=<span class="string">&#x27;batch-and-learn-%d&#x27;</span> % i, args=(i,device,position,locks[device][position],position_locks[position]))</span><br><span class="line">            thread.start()</span><br><span class="line">            threads.append(thread)</span><br></pre></td></tr></table></figure>
<p>最后，调用 <code>checkpoint</code> 函数输出检查点。</p>
<p>在解析代码之前，我们还需要先解释代码中观察到信息（obs）的命名，以便于后续的理解：</p>
<ul>
<li><code>z</code>: 最近 15 步历史移动信息。由于三家各走一步为一轮，所以编码是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mo>×</mo><mn>162</mn></mrow><annotation encoding="application/x-tex">5\times162</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mord">2</span></span></span></span> 而不是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>15</mn><mo>×</mo><mn>54</mn></mrow><annotation encoding="application/x-tex">15\times54</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">4</span></span></span></span>。</li>
<li><code>x_no_action</code>: 一堆特征，其中既没有动作特征，也不包括历史信息。</li>
<li><code>x_batch</code> : 一批次的特征，其中包括动作特征，不包括历史信息。</li>
<li><code>z_batch</code> : 被拓展为一个批次的历史移动信息。</li>
<li><code>legal_actions</code> : 合法的动作。</li>
</ul>
<p><img src="https://s2.loli.net/2025/04/30/fH3u7V9lmNjKznE.png" alt="图 4" /></p>
<p>由上表可以看出，<code>x_no_action</code> + <code>z</code> 就是我们所谓的 state。</p>
<p>所谓批次（batch）就是一堆同类的信息（或者更严谨的说，一堆独立的样本）。但是我们哪来一堆同类的信息？其实，一个批次里，每个样本都是一致的信息，以玩家手上的手牌为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_get_obs_landlord</span>(<span class="params">infoset</span>):</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    my_handcards = _cards2array(infoset.player_hand_cards)</span><br><span class="line">    my_handcards_batch = np.repeat(my_handcards[np.newaxis, :],</span><br><span class="line">                                   num_legal_actions, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>可以看见手牌的批次只是将手牌重复了 <code>num_legal_actions</code> 次。其实，之所以要拓展为批次，是为了在当前的 state 下，并行计算评估所有合法动作的价值，从而找出最有价值的动作。因此，也就需要将所有的 state 信息拓展为 <code>num_legal_actions</code> 个。因此，动作特征的批次就并不一样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_get_obs_landlord</span>(<span class="params">infoset</span>):</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    my_action_batch = np.zeros(my_handcards_batch.shape)</span><br><span class="line">    <span class="keyword">for</span> j, action <span class="keyword">in</span> <span class="built_in">enumerate</span>(infoset.legal_actions):</span><br><span class="line">        my_action_batch[j, :] = _cards2array(action)</span><br></pre></td></tr></table></figure>
<h3 id="act"><a class="markdownIt-Anchor" href="#act"></a> act()</h3>
<p><code>act</code> 函数是 <code>actor</code> 逻辑运行的地方。它会首先创建游戏环境（Environment），然后在这个环境下利用模型预测不断出牌，直到决出胜者，然后将这个过程中产生的数据传输到 <code>buffers</code> 中。随后，它再开一局新游戏，不断重复上述过程，直到我们打断它。如下图所示，其中粗线表现 <code>act()</code> 中的流转，细线表示该步的内部细节。</p>
<pre><code class="highlight mermaid">graph TD
GameEnv(GameEnv: GameSimulator)
Env(Env: multi-agent wrapper. *get reward, check finished, get_obs*)
Enviroment 
predict(model predict)
act(act func)
    subgraph step
        direction TB
        Enviroment --&gt; Env --&gt; GameEnv
        Env--&gt;env_step
    end
    subgraph env_step
        direction TB
         check_legal --&gt; GameEnvStep(&quot;do GameEnv.step()&quot;)--&gt;get_obs_landlord(get imperfect info from infoset by position)--&gt;get_reward(&quot;get reward when game end(+ for lanlord win,- for peasant win)&quot;)
    end
    subgraph forward
        direction TB
        Models.forward --&gt; LandlordLstmModel.forward--&gt;epsilon_greedy
        Models.forward --&gt; FarmerLstmModel.forward--&gt;epsilon_greedy
    end
act==&gt; predict ==&gt; performe(performe action)
performe--&gt;step
predict --&gt; forward</code></pre>
<h4 id="预测出牌forward"><a class="markdownIt-Anchor" href="#预测出牌forward"></a> 预测出牌：forward()</h4>
<p>前面的流程图中，<code>forward</code> 就是利用模型生成 <code>action</code> 的步骤。当然，如<code>## DouZero的算法逻辑</code> 一节的图所示，我们需要输入一些参数。简单来说，<code>act()</code> 调用 <code>model</code> 中的 <code>forward()</code> 函数获得数据，并对应更新 buf。如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">act</span>(<span class="params">...</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># some init steps</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                obs_x_no_action_buf[position].append(env_output[<span class="string">&#x27;obs_x_no_action&#x27;</span>])</span><br><span class="line">                obs_z_buf[position].append(env_output[<span class="string">&#x27;obs_z&#x27;</span>])</span><br><span class="line">                <span class="keyword">with</span> torch.no_grad(): </span><br><span class="line">                    agent_output = model.forward(position, obs[<span class="string">&#x27;z_batch&#x27;</span>], obs[<span class="string">&#x27;x_batch&#x27;</span>], flags=flags)</span><br></pre></td></tr></table></figure>
<p>model.forward() 根据 position 决定调用 LandlordLstmModel（地主）还是 FarmerLstmModel（农民）。它们的 forward 函数将一系列参数输入 Q网络（六层全连接）得到结果，并经历一次<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>−</mo><mi>g</mi><mi>r</mi><mi>e</mi><mi>e</mi><mi>d</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">\epsilon-greedy</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 得到结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LandlordLstmModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z, x, return_value=<span class="literal">False</span>, flags=<span class="literal">None</span></span>):</span><br><span class="line">        lstm_out, (h_n, _) = self.lstm(z)</span><br><span class="line">        lstm_out = lstm_out[:,-<span class="number">1</span>,:]</span><br><span class="line">        <span class="comment"># 六层全连接网络</span></span><br><span class="line">        x = torch.cat([lstm_out,x], dim=-<span class="number">1</span>)</span><br><span class="line">        x = self.dense1(x)</span><br><span class="line">        x = torch.relu(x)</span><br><span class="line">        x = self.dense2(x)</span><br><span class="line">        x = torch.relu(x)</span><br><span class="line">        x = self.dense3(x)</span><br><span class="line">        x = torch.relu(x)</span><br><span class="line">        x = self.dense4(x)</span><br><span class="line">        x = torch.relu(x)</span><br><span class="line">        x = self.dense5(x)</span><br><span class="line">        x = torch.relu(x)</span><br><span class="line">        x = self.dense6(x)</span><br><span class="line">        <span class="keyword">if</span> return_value:<span class="comment"># 如果设定为直接输出概率最大的结果</span></span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">dict</span>(values=x)</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># epsilon-greedy</span></span><br><span class="line">            <span class="keyword">if</span> flags <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> flags.exp_epsilon &gt; <span class="number">0</span> <span class="keyword">and</span> np.random.rand() &lt; flags.exp_epsilon:</span><br><span class="line">                action = torch.randint(x.shape[<span class="number">0</span>], (<span class="number">1</span>,))[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                action = torch.argmax(x,dim=<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">dict</span>(action=action)</span><br></pre></td></tr></table></figure>
<h4 id="执行操作step"><a class="markdownIt-Anchor" href="#执行操作step"></a> 执行操作：step()</h4>
<p>在这一步中，<code>actor</code>（或者说 <code>act()</code>）将 <code>forward()</code> 中确定的 <code>action</code> 编码并放进游戏中执行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">act</span>(<span class="params">...</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># some init steps</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                _action_idx = <span class="built_in">int</span>(agent_output[<span class="string">&#x27;action&#x27;</span>].cpu().detach().numpy())</span><br><span class="line">                action = obs[<span class="string">&#x27;legal_actions&#x27;</span>][_action_idx] </span><br><span class="line">                obs_action_buf[position].append(_cards2tensor(action))</span><br><span class="line">                size[position] += <span class="number">1</span></span><br><span class="line">                position, obs, env_output = env.step(action)</span><br></pre></td></tr></table></figure>
<p><code>env</code>，即游戏环境，如前面的 <code>act() 流程图</code> 所示，在源代码中共有三层，从顶到底分别是 <code>Environment</code>，<code>Env</code> 和 <code>GameEnv</code>。</p>
<p>最底层的 GameEnv 是纯粹的游戏模拟逻辑，它根据 action 更新玩家手牌、指定下一个玩家出牌的玩家、判断游戏有没有结束、收集场上信息（infoset）……如下：（有简化）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GameEnv</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self</span>):</span><br><span class="line">        action = self.players[self.acting_player_position].act(self.game_infoset) <span class="comment"># 获取玩家类（dummyAgent）中的动作</span></span><br><span class="line">        <span class="keyword">assert</span> action <span class="keyword">in</span> self.game_infoset.legal_actions <span class="comment"># 断言动作是合法的</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(action) &gt; <span class="number">0</span>:</span><br><span class="line">            self.last_pid = self.acting_player_position</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> action <span class="keyword">in</span> bombs:</span><br><span class="line">            self.bomb_num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.last_move_dict[self.acting_player_position] = action.copy()</span><br><span class="line"></span><br><span class="line">        self.card_play_action_seq.append(action)</span><br><span class="line">        self.update_acting_player_hand_cards(action) <span class="comment">#更新手牌</span></span><br><span class="line"></span><br><span class="line">        self.played_cards[self.acting_player_position] += action</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 检查游戏状态并更新信息集</span></span><br><span class="line">        self.game_done()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.game_over:</span><br><span class="line">            self.get_acting_player_position()</span><br><span class="line">            self.game_infoset = self.get_infoset()</span><br></pre></td></tr></table></figure>
<p><code>Env</code> 是 <code>GameEnv</code> 的一层抽象。使用它的目的是“分离玩家和游戏，让接口更有 <code>OpenAI Gym</code> 的风格”（<code>class Env</code>, <code>def init()</code>,“isolate players and environments to have a more gym style interface.”）。更具体来说，<code>Env</code> 除了将动作传递到 <code>GameEnv</code> 中执行以外，还将 <code>GameEnv</code> 中的完美信息集合（infoset） 变成并不完美的信息集合：显然，每个玩家都不可能观察到别的玩家的手牌，玩家的信息是不完整的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self, action</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Step function takes as input the action, which</span></span><br><span class="line"><span class="string">    is a list of integers, and output the next observation,</span></span><br><span class="line"><span class="string">    reward, and a Boolean variable indicating whether the</span></span><br><span class="line"><span class="string">    current game is finished. It also returns an empty</span></span><br><span class="line"><span class="string">    dictionary that is reserved to pass useful information.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> action <span class="keyword">in</span> self.infoset.legal_actions</span><br><span class="line">    self.players[self._acting_player_position].set_action(action) <span class="comment"># 将动作传递给玩家（DummyAgent），GameEnv 稍后会从这里取出它们</span></span><br><span class="line">    self._env.step() <span class="comment"># 所以这里无需传参</span></span><br><span class="line">    self.infoset = self._game_infoset</span><br><span class="line">    done = <span class="literal">False</span></span><br><span class="line">    reward = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">if</span> self._game_over:</span><br><span class="line">        done = <span class="literal">True</span></span><br><span class="line">        reward = self._get_reward()</span><br><span class="line">        obs = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        obs = get_obs(self.infoset) <span class="comment"># 从 infoset 中根据 position 获取不完美的观察信息</span></span><br><span class="line">    <span class="keyword">return</span> obs, reward, done, &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>最顶层的 <code>Enviroment</code> 负责将观察信息通过 CUDA 转化为张量，并在游戏结束时，自动重置游戏。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_format_observation</span>(<span class="params">obs, device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A utility function to process observations and</span></span><br><span class="line"><span class="string">    move them to CUDA.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    position = obs[<span class="string">&#x27;position&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> device == <span class="string">&quot;cpu&quot;</span>:</span><br><span class="line">        device = <span class="string">&#x27;cuda:&#x27;</span> + <span class="built_in">str</span>(device)</span><br><span class="line">    device = torch.device(device)</span><br><span class="line">    x_batch = torch.from_numpy(obs[<span class="string">&#x27;x_batch&#x27;</span>]).to(device)</span><br><span class="line">    z_batch = torch.from_numpy(obs[<span class="string">&#x27;z_batch&#x27;</span>]).to(device)</span><br><span class="line">    x_no_action = torch.from_numpy(obs[<span class="string">&#x27;x_no_action&#x27;</span>])</span><br><span class="line">    z = torch.from_numpy(obs[<span class="string">&#x27;z&#x27;</span>])</span><br><span class="line">    obs = &#123;<span class="string">&#x27;x_batch&#x27;</span>: x_batch,</span><br><span class="line">           <span class="string">&#x27;z_batch&#x27;</span>: z_batch,</span><br><span class="line">           <span class="string">&#x27;legal_actions&#x27;</span>: obs[<span class="string">&#x27;legal_actions&#x27;</span>],</span><br><span class="line">           &#125;</span><br><span class="line">    <span class="keyword">return</span> position, obs, x_no_action, z</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Environment</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self, action</span>):</span><br><span class="line">        obs, reward, done, _ = self.env.step(action)</span><br><span class="line"></span><br><span class="line">        self.episode_return += reward</span><br><span class="line">        episode_return = self.episode_return </span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            obs = self.env.reset()</span><br><span class="line">            self.episode_return = torch.zeros(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        position, obs, x_no_action, z = _format_observation(obs, self.device)</span><br><span class="line">        reward = torch.tensor(reward).view(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        done = torch.tensor(done).view(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> position, obs, <span class="built_in">dict</span>(</span><br><span class="line">            done=done,</span><br><span class="line">            episode_return=episode_return,</span><br><span class="line">            obs_x_no_action=x_no_action,</span><br><span class="line">            obs_z=z,</span><br><span class="line">            )</span><br></pre></td></tr></table></figure>
<h4 id="传递信息"><a class="markdownIt-Anchor" href="#传递信息"></a> 传递信息</h4>
<p>最后，完成一局游戏，我们将数据传送到共享缓存中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> positions:</span><br><span class="line">    <span class="keyword">while</span> size[p] &gt; T: <span class="comment"># 每次传送 T 个数据</span></span><br><span class="line">        index = free_queue[p].get() <span class="comment"># 请求 T 个槽位以供写入</span></span><br><span class="line">        <span class="keyword">if</span> index <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(T): <span class="comment"># 将前 T 步数据复制到共享缓冲区 buffers 中</span></span><br><span class="line">            buffers[p][<span class="string">&#x27;done&#x27;</span>][index][t, ...] = done_buf[p][t]</span><br><span class="line">            buffers[p][<span class="string">&#x27;episode_return&#x27;</span>][index][t, ...] = episode_return_buf[p][t]</span><br><span class="line">            buffers[p][<span class="string">&#x27;target&#x27;</span>][index][t, ...] = target_buf[p][t]</span><br><span class="line">            buffers[p][<span class="string">&#x27;obs_x_no_action&#x27;</span>][index][t, ...] = obs_x_no_action_buf[p][t]</span><br><span class="line">            buffers[p][<span class="string">&#x27;obs_action&#x27;</span>][index][t, ...] = obs_action_buf[p][t]</span><br><span class="line">            buffers[p][<span class="string">&#x27;obs_z&#x27;</span>][index][t, ...] = obs_z_buf[p][t]</span><br><span class="line">        full_queue[p].put(index) <span class="comment"># 对应标记这些槽位已被填满</span></span><br><span class="line">        done_buf[p] = done_buf[p][T:] <span class="comment"># 清除前 T 被读取了的元素，</span></span><br><span class="line">        episode_return_buf[p] = episode_return_buf[p][T:]</span><br><span class="line">        target_buf[p] = target_buf[p][T:]</span><br><span class="line">        obs_x_no_action_buf[p] = obs_x_no_action_buf[p][T:]</span><br><span class="line">        obs_action_buf[p] = obs_action_buf[p][T:]</span><br><span class="line">        obs_z_buf[p] = obs_z_buf[p][T:]</span><br><span class="line">        size[p] -= T</span><br></pre></td></tr></table></figure>
<h3 id="batch_and_learn"><a class="markdownIt-Anchor" href="#batch_and_learn"></a> batch_and_learn()</h3>
<p><code>batch_and_learn</code> 即学习的主函数，这个程序根据 <code>actor</code> 的数据进行学习，并更新 <code>actor</code> 的 <code>model</code>。如下：</p>
<pre><code class="highlight mermaid">graph TB
BL(&quot;batch_and_learn()&quot;)
L(&quot;Learn()&quot;)
U(&quot;Update()：update player model with lock&quot;)
Log(&quot;Update Log&quot;)
BL ==&gt; L==&gt;U
%% L--&gt;Learn
subgraph Learn
handle(&quot;handle data&quot;)
loss(&quot;calculate MSE loss&quot;)
backward(&quot;backward propagation (calculate grad)&quot;)
actor(&quot;update actor models&quot;)
L--&gt;handle--&gt;loss--&gt;backward--&gt;actor
end
U==&gt;Log</code></pre>
<p>在数据处理中，我们首先将观察信息中的 <code>x_no_action</code> 和 <code>action</code> 组合为 <code>x</code>（即 <code>state</code> + <code>action</code> - <code>历史移动信息</code>）。然后将 <code>x</code>、<code>z</code>、<code>target</code> 都展平，因为我们的网络是全连接的。此外，还计算了游戏的平均回报。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">obs_x_no_action = batch[<span class="string">&#x27;obs_x_no_action&#x27;</span>].to(device)</span><br><span class="line">obs_action = batch[<span class="string">&#x27;obs_action&#x27;</span>].to(device)</span><br><span class="line">obs_x = torch.cat((obs_x_no_action, obs_action), dim=<span class="number">2</span>).<span class="built_in">float</span>()</span><br><span class="line">obs_x = torch.flatten(obs_x, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">obs_z = torch.flatten(batch[<span class="string">&#x27;obs_z&#x27;</span>].to(device), <span class="number">0</span>, <span class="number">1</span>).<span class="built_in">float</span>()</span><br><span class="line">target = torch.flatten(batch[<span class="string">&#x27;target&#x27;</span>].to(device), <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">episode_returns = batch[<span class="string">&#x27;episode_return&#x27;</span>][batch[<span class="string">&#x27;done&#x27;</span>]]</span><br><span class="line">mean_episode_return_buf[position].append(torch.mean(episode_returns).to(device))</span><br></pre></td></tr></table></figure>
<p>随后，在加锁以后，我们开始修改模型。</p>
<p>首先，我们通过 MSE 公式计算损失。前面提到，它的公式为：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>×</mo><mo>∑</mo><mo stretchy="false">(</mo><mi>a</mi><mi>c</mi><mi>t</mi><mi>u</mi><mi>a</mi><mi>l</mi><mtext>–</mtext><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">MSE = \frac{1}{n}\times \sum(actual – prediction)^2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.6000100000000002em;vertical-align:-0.55001em;"></span><span class="mop op-symbol large-op" style="position:relative;top:-0.000004999999999977245em;">∑</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">u</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord">–</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_loss</span>(<span class="params">logits, targets</span>):</span><br><span class="line">    loss = ((logits.squeeze(-<span class="number">1</span>) - targets)**<span class="number">2</span>).mean()</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<p>清除历史梯度，然后计算损失的梯度，并反向传播更新模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">optimizer.zero_grad() <span class="comment"># 清除历史梯度</span></span><br><span class="line">loss.backward() <span class="comment"># 计算损失的梯度</span></span><br><span class="line">nn.utils.clip_grad_norm_(model.parameters(), flags.max_grad_norm) <span class="comment"># 限制模型最大梯度</span></span><br><span class="line">optimizer.step() <span class="comment"># 反向传播，更新模型</span></span><br></pre></td></tr></table></figure>
<p>最后，同步到 <code>actor</code> 模型上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> actor_model <span class="keyword">in</span> actor_models.values():</span><br><span class="line">    actor_model.get_model(position).load_state_dict(model.state_dict())</span><br></pre></td></tr></table></figure>
<h2 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献</h2>
<ol>
<li>Douzero GitHub 开源代码：<a href="https://github.com/kwai/DouZero?tab=readme-ov-file">kwai/DouZero: [ICML 2021] DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning | 斗地主AI</a></li>
<li>作者中文博文：<a href="https://zhuanlan.zhihu.com/p/526723604">DouZero斗地主AI深度解析，以及RLCard工具包介绍 - 知乎</a></li>
<li>《Easy RL》，第一章 强化学习基础: <a href="https://datawhalechina.github.io/easy-rl/#/chapter1/chapter1">第一章 强化学习基础</a></li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/" rel="tag"><i class="fa fa-tag"></i> 蒙特卡洛方法</a>
              <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 强化学习</a>
              <a href="/tags/%E6%96%97%E5%9C%B0%E4%B8%BB/" rel="tag"><i class="fa fa-tag"></i> 斗地主</a>
              <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a>
              <a href="/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/" rel="tag"><i class="fa fa-tag"></i> 读论文</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/post/20250321023639.html" rel="prev" title="聊聊天国拯救的剧情">
                  <i class="fa fa-angle-left"></i> 聊聊天国拯救的剧情
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/post/20250501165336.html" rel="next" title="在VSC上使用Typecript刷LeetCode">
                  在VSC上使用Typecript刷LeetCode <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2020 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">LeeKa</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">145k</span>
  </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>



  <script src="/js/third-party/pace.js"></script>


  




<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"leekapub","count":true,"i18n":{"disqus":"disqus"}}</script>
<script src="/js/third-party/comments/disqus.js"></script>

</body>
</html>
